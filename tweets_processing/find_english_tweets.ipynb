{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "find_english_tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_WTU2AxsW6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas and language detection module\n",
        "import langid\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('ghana_election.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adb3U5Syssw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ensure report column is of type string\n",
        "df['report'] = df['report'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBsfajQNsye5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all English tweets\n",
        "idx_english_tweets = []\n",
        "\n",
        "# for each tweet in dataframe\n",
        "for idx, tweet in enumerate(df['report']):\n",
        "  # if the tweet length is greater than two and langid module classifies it as English\n",
        "  if len(tweet) > 2 and langid.classify(tweet)[0] == 'en':\n",
        "\n",
        "    # save the tweet id\n",
        "    idx_english_tweets.append(idx)\n",
        "\n",
        "# save english tweet indices in csv\n",
        "english_idx_df = pd.DataFrame(idx_english_tweets, columns=[\"english_id\"])\n",
        "english_idx_df.to_csv('idx_english_tweets.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}